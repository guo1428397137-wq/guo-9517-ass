{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUSiR32ZtJ0QaPHou1wlur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guo1428397137-wq/guo-9517-ass/blob/Faster-R-CNN/Faster-R-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTrWxGvVTw-B"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics opencv-python tqdm\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/archive\")\n",
        "\n",
        "TRAIN_IMG_DIR   = DATA_ROOT / \"train\" / \"images\"\n",
        "TRAIN_LABEL_DIR = DATA_ROOT / \"train\" / \"labels\"\n",
        "VAL_IMG_DIR     = DATA_ROOT / \"valid\" / \"images\"\n",
        "VAL_LABEL_DIR   = DATA_ROOT / \"valid\" / \"labels\"\n",
        "TEST_IMG_DIR    = DATA_ROOT / \"test\" / \"images\"\n",
        "TEST_LABEL_DIR  = DATA_ROOT / \"test\" / \"labels\"\n",
        "\n",
        "NUM_CLASSES   = 12\n",
        "BATCH_SIZE    = 4\n",
        "IMG_MAX_SIZE  = 800\n",
        "EPOCHS        = 20\n",
        "LR            = 0.001\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Dataset Category Name\n",
        "CLASS_NAMES = [\n",
        "    'background',  # 0\n",
        "    'Ants', 'Bees', 'Beetle', 'Caterpillar',\n",
        "    'Earthworms', 'Earwig', 'Grasshopper', 'Moth',\n",
        "    'Slug', 'Snail', 'Wasp', 'Weevil'\n",
        "]\n",
        "\n",
        "# Improved tag loading function\n",
        "def load_yolo_labels(label_path: Path, img_w: int, img_h: int):\n",
        "\n",
        "    if not label_path.exists():\n",
        "        return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "    try:\n",
        "        data = np.loadtxt(str(label_path), ndmin=2)\n",
        "    except:\n",
        "        return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "    if data.shape[0] == 0:\n",
        "        return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "    cls = data[:, 0].astype(np.int64)\n",
        "    cx  = data[:, 1] * img_w\n",
        "    cy  = data[:, 2] * img_h\n",
        "    bw  = data[:, 3] * img_w\n",
        "    bh  = data[:, 4] * img_h\n",
        "\n",
        "    x1 = np.clip(cx - bw / 2, 0, img_w)\n",
        "    y1 = np.clip(cy - bh / 2, 0, img_h)\n",
        "    x2 = np.clip(cx + bw / 2, 0, img_w)\n",
        "    y2 = np.clip(cy + bh / 2, 0, img_h)\n",
        "\n",
        "    # Invalid filter box\n",
        "    valid = (x2 > x1) & (y2 > y1)\n",
        "    if not valid.any():\n",
        "        return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "    boxes = np.stack([x1[valid], y1[valid], x2[valid], y2[valid]], axis=1).astype(np.float32)\n",
        "    labels = cls[valid] + 1\n",
        "\n",
        "    return torch.as_tensor(boxes, dtype=torch.float32), torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "\n",
        "def resize_keep_ratio(img: np.ndarray, target: Dict[str, Any], max_size: int):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    scale = min(max_size / max(h, w), 1.0)\n",
        "    nh, nw = int(h * scale), int(w * scale)\n",
        "\n",
        "    if (nh, nw) != (h, w):\n",
        "        img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
        "        if target[\"boxes\"].numel() > 0:\n",
        "            boxes = target[\"boxes\"]\n",
        "            boxes[:, [0, 2]] *= float(nw) / w\n",
        "            boxes[:, [1, 3]] *= float(nh) / h\n",
        "            boxes[:, 0] = torch.clamp(boxes[:, 0], 0, nw)\n",
        "            boxes[:, 1] = torch.clamp(boxes[:, 1], 0, nh)\n",
        "            boxes[:, 2] = torch.clamp(boxes[:, 2], 0, nw)\n",
        "            boxes[:, 3] = torch.clamp(boxes[:, 3], 0, nh)\n",
        "            target[\"boxes\"] = boxes\n",
        "\n",
        "    target[\"size\"] = torch.tensor([nh, nw], dtype=torch.int64)\n",
        "    return img, target\n",
        "\n",
        "\n",
        "\n",
        "# Dataset\n",
        "\n",
        "class YoloDetectionDataset(Dataset):\n",
        "    def __init__(self, img_dir: Path, label_dir: Path, training: bool = True, img_max_size: int = 800):\n",
        "        self.img_dir   = Path(img_dir)\n",
        "        self.label_dir = Path(label_dir)\n",
        "        self.training  = training\n",
        "        self.img_max_size = img_max_size\n",
        "\n",
        "        exts = [\".jpg\", \".jpeg\", \".png\"]\n",
        "        self.img_paths = [p for p in self.img_dir.rglob(\"*\") if p.suffix.lower() in exts]\n",
        "        self.img_paths.sort()\n",
        "\n",
        "        if len(self.img_paths) == 0:\n",
        "            raise RuntimeError(f\"No images found in {self.img_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label_path = self.label_dir / (img_path.stem + \".txt\")\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        boxes, labels = load_yolo_labels(label_path, w, h)\n",
        "\n",
        "        if boxes.numel() > 0:\n",
        "            area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
        "        else:\n",
        "            area = torch.zeros((0,), dtype=torch.float32)\n",
        "\n",
        "        iscrowd = torch.zeros((labels.shape[0],), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\":    boxes,\n",
        "            \"labels\":   labels,\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "            \"area\":     area,\n",
        "            \"iscrowd\":  iscrowd,\n",
        "        }\n",
        "\n",
        "        if self.training and boxes.numel() > 0:\n",
        "\n",
        "            if np.random.rand() < 0.5:\n",
        "                img = np.ascontiguousarray(img[:, ::-1])\n",
        "                w_img = img.shape[1]\n",
        "                b = target[\"boxes\"].clone()\n",
        "                x1 = b[:, 0].clone()\n",
        "                x2 = b[:, 2].clone()\n",
        "                b[:, 0] = w_img - x2\n",
        "                b[:, 2] = w_img - x1\n",
        "                target[\"boxes\"] = b\n",
        "\n",
        "\n",
        "            if np.random.rand() < 0.3:\n",
        "                img = cv2.convertScaleAbs(img, alpha=np.random.uniform(0.8, 1.2),\n",
        "                                         beta=np.random.uniform(-10, 10))\n",
        "\n",
        "\n",
        "        img, target = resize_keep_ratio(img, target, self.img_max_size)\n",
        "\n",
        "\n",
        "        img = TF.to_tensor(img)\n",
        "        img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs, targets = list(zip(*batch))\n",
        "    return list(imgs), list(targets)\n",
        "\n",
        "\n",
        "# Create a dataset\n",
        "train_dataset = YoloDetectionDataset(TRAIN_IMG_DIR, TRAIN_LABEL_DIR, training=True, img_max_size=IMG_MAX_SIZE)\n",
        "val_dataset   = YoloDetectionDataset(VAL_IMG_DIR, VAL_LABEL_DIR, training=False, img_max_size=IMG_MAX_SIZE)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=2, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
        "\n",
        "\n",
        "print(\"\\ncheck first sample:\")\n",
        "img, target = train_dataset[0]\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Boxes shape: {target['boxes'].shape}\")\n",
        "print(f\"Labels: {target['labels']}\")\n",
        "print(f\"Boxes: {target['boxes'][:5] if len(target['boxes']) > 0 else 'No boxes'}\")\n",
        "\n",
        "# model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES + 1)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print(f\"\\nModel parameter count: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "\n",
        "# optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=LR, momentum=0.9, weight_decay=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "\n",
        "# Training and validation\n",
        "def train_one_epoch(epoch: int):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f\"[Train] Epoch {epoch}\")\n",
        "    running_loss = 0.0\n",
        "    loss_components = {'cls': 0, 'box': 0, 'obj': 0, 'rpn': 0}\n",
        "\n",
        "    for images, targets in pbar:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            loss_dict = model(images, targets)\n",
        "            loss = sum(loss_dict.values())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loss_components['cls'] += loss_dict.get('loss_classifier', torch.tensor(0)).item()\n",
        "        loss_components['box'] += loss_dict.get('loss_box_reg', torch.tensor(0)).item()\n",
        "        loss_components['obj'] += loss_dict.get('loss_objectness', torch.tensor(0)).item()\n",
        "        loss_components['rpn'] += loss_dict.get('loss_rpn_box_reg', torch.tensor(0)).item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{loss.item():.3f}\",\n",
        "            \"cls\":  f\"{loss_dict.get('loss_classifier', torch.tensor(0)).item():.3f}\",\n",
        "            \"box\":  f\"{loss_dict.get('loss_box_reg', torch.tensor(0)).item():.3f}\",\n",
        "        })\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    n = len(train_loader)\n",
        "    return running_loss / n, {k: v/n for k, v in loss_components.items()}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_map():\n",
        "    model.eval()\n",
        "    metric = MeanAveragePrecision(\n",
        "    iou_type=\"bbox\",\n",
        "    iou_thresholds=[0.3]\n",
        ")\n",
        "    pbar = tqdm(val_loader, desc=\"[Eval]\")\n",
        "\n",
        "    for images, targets in pbar:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "\n",
        "        preds, gts = [], []\n",
        "        for out, tgt in zip(outputs, targets):\n",
        "            preds.append({\n",
        "                \"boxes\":  out[\"boxes\"].detach().cpu(),\n",
        "                \"scores\": out[\"scores\"].detach().cpu(),\n",
        "                \"labels\": out[\"labels\"].detach().cpu(),\n",
        "            })\n",
        "            gts.append({\n",
        "                \"boxes\":   tgt[\"boxes\"].detach().cpu(),\n",
        "                \"labels\":  tgt[\"labels\"].detach().cpu(),\n",
        "                \"iscrowd\": tgt.get(\"iscrowd\", torch.zeros((tgt[\"labels\"].shape[0],), dtype=torch.int64)).detach().cpu()\n",
        "            })\n",
        "        metric.update(preds, gts)\n",
        "\n",
        "    res = metric.compute()\n",
        "    out = {}\n",
        "    if \"map\" in res:\n",
        "        out[\"map\"] = res[\"map\"].item()\n",
        "    if \"map_50\" in res:\n",
        "        out[\"map_50\"] = res[\"map_50\"].item()\n",
        "    if \"map_75\" in res:\n",
        "        out[\"map_75\"] = res[\"map_75\"].item()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "best_map = 0.0\n",
        "history = {'train_loss': [], 'map': [], 'map_50': []}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Start training\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, loss_comp = train_one_epoch(epoch)\n",
        "    metrics = evaluate_map()\n",
        "    map_all = metrics[\"map\"]\n",
        "    map_50  = metrics[\"map_50\"]\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['map'].append(map_all)\n",
        "    history['map_50'].append(map_50)\n",
        "\n",
        "    print(f\"[Epoch {epoch:02d}] \"\n",
        "          f\"train_loss={train_loss:.4f}  \"\n",
        "          f\"mAP={map_all:.4f}  \"\n",
        "          f\"mAP50={map_50:.4f}\")\n",
        "    print(f\"  Loss components: cls={loss_comp['cls']:.4f}, box={loss_comp['box']:.4f}, \"\n",
        "          f\"obj={loss_comp['obj']:.4f}, rpn={loss_comp['rpn']:.4f}\")\n",
        "\n",
        "    if map_all > best_map:\n",
        "        best_map = map_all\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'map': map_all,\n",
        "        }, \"/content/fasterrcnn_best.pth\")\n",
        "        print(\"  ðŸ‘‰ Saved new best model.\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "print(f\"\\nTraining completed Best mAP = {best_map:.4f}\")\n",
        "\n",
        "# Plotting training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(history['train_loss'], marker='o', label='Train Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(history['map'], marker='o', label='mAP')\n",
        "axes[1].plot(history['map_50'], marker='s', label='mAP@50')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('mAP')\n",
        "axes[1].set_title('Validation mAP')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualization Functions\n",
        "def denormalize_image(img_tensor):\n",
        "\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img = img_tensor * std + mean\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    return img.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Visualize the prediction results\n",
        "def visualize_predictions(dataset: Dataset, num_images: int = 6, score_thresh: float = 0.05):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    idxs = random.sample(range(len(dataset)), k=min(num_images, len(dataset)))\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, idx in enumerate(idxs):\n",
        "        img, target = dataset[idx]\n",
        "\n",
        "        img_np = denormalize_image(img.cpu())\n",
        "\n",
        "        # predict\n",
        "        with torch.no_grad():\n",
        "            out = model([img.to(device)])[0]\n",
        "\n",
        "        boxes  = out[\"boxes\"].cpu().numpy()\n",
        "        scores = out[\"scores\"].cpu().numpy()\n",
        "        labels = out[\"labels\"].cpu().numpy()\n",
        "\n",
        "        keep = scores >= score_thresh\n",
        "        boxes, scores, labels = boxes[keep], scores[keep], labels[keep]\n",
        "\n",
        "        vis = (img_np * 255).astype(np.uint8).copy()\n",
        "\n",
        "        # Draw the prediction box\n",
        "        for (x1, y1, x2, y2), s, lb in zip(boxes, scores, labels):\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "            cv2.rectangle(vis, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "            class_name = CLASS_NAMES[int(lb)] if int(lb) < len(CLASS_NAMES) else str(int(lb))\n",
        "            text = f\"{class_name}: {s:.2f}\"\n",
        "\n",
        "            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "            cv2.rectangle(vis, (x1, max(0, y1-text_h-5)), (x1+text_w, y1), (255, 0, 0), -1)\n",
        "            cv2.putText(vis, text, (x1, max(text_h, y1-5)),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "        # Draw a realistic outline\n",
        "        gt_boxes = target[\"boxes\"].numpy()\n",
        "        gt_labels = target[\"labels\"].numpy()\n",
        "        for (x1, y1, x2, y2), lb in zip(gt_boxes, gt_labels):\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "            cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        axes[i].imshow(vis)\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Sample {idx} | Pred: {len(boxes)} boxes', fontsize=10, fontweight='bold')\n",
        "\n",
        "\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='red', edgecolor='red', label='Prediction'),\n",
        "        Patch(facecolor='green', edgecolor='green', label='Ground Truth')\n",
        "    ]\n",
        "    fig.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/predictions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nVisualize the prediction results:\")\n",
        "visualize_predictions(val_dataset, num_images=6, score_thresh=0.05)\n",
        "\n",
        "# Evaluate\n",
        "\n",
        "@torch.no_grad()\n",
        "def detailed_evaluation(dataset, score_thresh=0.5):\n",
        "    model.eval()\n",
        "\n",
        "    class_tp = {i: 0 for i in range(1, NUM_CLASSES+1)}\n",
        "    class_fp = {i: 0 for i in range(1, NUM_CLASSES+1)}\n",
        "    class_fn = {i: 0 for i in range(1, NUM_CLASSES+1)}\n",
        "\n",
        "    for idx in tqdm(range(len(dataset)), desc='Detailed Eval'):\n",
        "        img, target = dataset[idx]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model([img.to(device)])[0]\n",
        "\n",
        "        pred_boxes = out[\"boxes\"].cpu().numpy()\n",
        "        pred_scores = out[\"scores\"].cpu().numpy()\n",
        "        pred_labels = out[\"labels\"].cpu().numpy()\n",
        "\n",
        "        keep = pred_scores >= score_thresh\n",
        "        pred_labels = pred_labels[keep]\n",
        "\n",
        "        gt_labels = target[\"labels\"].numpy()\n",
        "\n",
        "\n",
        "        for label in range(1, NUM_CLASSES+1):\n",
        "            n_pred = np.sum(pred_labels == label)\n",
        "            n_gt = np.sum(gt_labels == label)\n",
        "\n",
        "            if n_gt > 0:\n",
        "                if n_pred > 0:\n",
        "                    class_tp[label] += min(n_pred, n_gt)\n",
        "                    if n_pred > n_gt:\n",
        "                        class_fp[label] += (n_pred - n_gt)\n",
        "                    else:\n",
        "                        class_fn[label] += (n_gt - n_pred)\n",
        "                else:\n",
        "                    class_fn[label] += n_gt\n",
        "            else:\n",
        "                if n_pred > 0:\n",
        "                    class_fp[label] += n_pred\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Performance of each category:\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"{'Class':<15} {'TP':>6} {'FP':>6} {'FN':>6} {'Precision':>10} {'Recall':>10} {'F1':>10}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    for label in range(1, NUM_CLASSES+1):\n",
        "        tp = class_tp[label]\n",
        "        fp = class_fp[label]\n",
        "        fn = class_fn[label]\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        class_name = CLASS_NAMES[label] if label < len(CLASS_NAMES) else f\"Class_{label}\"\n",
        "        print(f\"{class_name:<15} {tp:6d} {fp:6d} {fn:6d} {precision:10.4f} {recall:10.4f} {f1:10.4f}\")\n",
        "\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# run\n",
        "detailed_evaluation(val_dataset, score_thresh=0.05)\n",
        "\n"
      ]
    }
  ]
}